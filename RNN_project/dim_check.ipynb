{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils import rnn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "# from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vectors,GloVe\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:44, 5.24MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [01:08<00:00, 5829.78it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 30000\n",
    "glove = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.vocab.vectors.GloVe'>\n"
     ]
    }
   ],
   "source": [
    "print(type(glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.3712e-01, -2.1691e-01, -6.6365e-03, -4.1625e-01, -1.2555e+00,\n",
       "        -2.8466e-02, -7.2195e-01, -5.2887e-01,  7.2085e-03,  3.1997e-01,\n",
       "         2.9425e-02, -1.3236e-02,  4.3511e-01,  2.5716e-01,  3.8995e-01,\n",
       "        -1.1968e-01,  1.5035e-01,  4.4762e-01,  2.8407e-01,  4.9339e-01,\n",
       "         6.2826e-01,  2.2888e-01, -4.0385e-01,  2.7364e-02,  7.3679e-03,\n",
       "         1.3995e-01,  2.3346e-01,  6.8122e-02,  4.8422e-01, -1.9578e-02,\n",
       "        -5.4751e-01, -5.4983e-01, -3.4091e-02,  8.0017e-03, -4.3065e-01,\n",
       "        -1.8969e-02, -8.5670e-02, -8.1123e-01, -2.1080e-01,  3.7784e-01,\n",
       "        -3.5046e-01,  1.3684e-01, -5.5661e-01,  1.6835e-01, -2.2952e-01,\n",
       "        -1.6184e-01,  6.7345e-01, -4.6597e-01, -3.1834e-02, -2.6037e-01,\n",
       "        -1.7797e-01,  1.9436e-02,  1.0727e-01,  6.6534e-01, -3.4836e-01,\n",
       "         4.7833e-02,  1.6440e-01,  1.4088e-01,  1.9204e-01, -3.5009e-01,\n",
       "         2.6236e-01,  1.7626e-01, -3.1367e-01,  1.1709e-01,  2.0378e-01,\n",
       "         6.1775e-01,  4.9075e-01, -7.5210e-02, -1.1815e-01,  1.8685e-01,\n",
       "         4.0679e-01,  2.8319e-01, -1.6290e-01,  3.8388e-02,  4.3794e-01,\n",
       "         8.8224e-02,  5.9046e-01, -5.3515e-02,  3.8819e-02,  1.8202e-01,\n",
       "        -2.7599e-01,  3.9474e-01, -2.0499e-01,  1.7411e-01,  1.0315e-01,\n",
       "         2.5117e-01, -3.6542e-01,  3.6528e-01,  2.2448e-01, -9.7551e-01,\n",
       "         9.4505e-02, -1.7859e-01, -3.0688e-01, -5.8633e-01, -1.8526e-01,\n",
       "         3.9565e-02, -4.2309e-01, -1.5715e-01,  2.0401e-01,  1.6906e-01,\n",
       "         3.4465e-01, -4.2262e-01,  1.9553e-01,  5.9454e-01, -3.0531e-01,\n",
       "        -1.0633e-01, -1.9055e-01, -5.8544e-01,  2.1357e-01,  3.8414e-01,\n",
       "         9.1499e-02,  3.8353e-01,  2.9075e-01,  2.4519e-02,  2.8440e-01,\n",
       "         6.3715e-02, -1.5483e-01,  4.0031e-01,  3.1543e-01, -3.7128e-02,\n",
       "         6.3363e-02, -2.7090e-01,  2.5160e-01,  4.7105e-01,  4.9556e-01,\n",
       "        -3.6401e-01,  1.0370e-01,  4.6076e-02,  1.6565e-01, -2.9024e-01,\n",
       "        -6.6949e-02, -3.0881e-01,  4.8263e-01,  3.0972e-01, -1.1145e-01,\n",
       "        -1.0329e-01,  2.8585e-02, -1.3579e-01,  5.2924e-01, -1.4077e-01,\n",
       "         9.1763e-02,  1.3127e-01, -2.0944e-01,  2.2327e-02, -7.7692e-02,\n",
       "         7.7934e-02, -3.3067e-02,  1.1680e-01,  3.2029e-01,  3.7749e-01,\n",
       "        -7.5679e-01, -1.5944e-01,  1.4964e-01,  4.2253e-01,  2.8136e-03,\n",
       "         2.1328e-01,  8.6776e-02, -5.2704e-02, -4.0859e-01, -1.1774e-01,\n",
       "         9.0621e-02, -2.3794e-01, -1.8326e-01,  1.3115e-01, -5.5949e-01,\n",
       "         9.2071e-02, -3.9504e-02,  1.3334e-01,  4.9632e-01,  2.8733e-01,\n",
       "        -1.8544e-01,  2.4618e-02, -4.2826e-01,  7.4148e-02,  7.6584e-04,\n",
       "         2.3950e-01,  2.2615e-01,  5.5166e-02, -7.5096e-02, -2.2308e-01,\n",
       "         2.3775e-01, -4.5455e-01,  2.6564e-01, -1.5137e-01, -2.4146e-01,\n",
       "        -2.4736e-01,  5.5214e-01,  2.6819e-01,  4.8831e-01, -1.3423e-01,\n",
       "        -1.5918e-01,  3.7606e-01, -1.9834e-01,  1.6699e-01, -1.5368e-01,\n",
       "         2.4561e-01, -9.2506e-02, -3.0257e-01, -2.9493e-01, -7.4917e-01,\n",
       "         1.0567e+00,  3.7971e-01,  6.9314e-01, -3.1672e-02,  2.1588e-01,\n",
       "        -4.0739e-01, -1.5264e-01,  3.2296e-01, -1.2999e-01, -5.0129e-01,\n",
       "        -4.4231e-01,  1.6904e-02, -1.1459e-02,  7.2293e-03,  1.1026e-01,\n",
       "         2.1568e-01, -3.2373e-01, -3.7292e-01, -9.2456e-03, -2.6769e-01,\n",
       "         3.9066e-01,  3.5742e-01, -6.0632e-02,  6.7966e-02,  3.3830e-01,\n",
       "         6.5747e-02,  1.5794e-01,  4.7155e-02,  2.3682e-01, -9.1370e-02,\n",
       "         6.4649e-01, -2.5491e-01, -6.7940e-01, -6.9752e-01, -1.0145e-01,\n",
       "        -3.6255e-01,  3.6967e-01, -4.1295e-01,  8.2724e-02, -3.5053e-01,\n",
       "        -1.7564e-01,  8.5095e-02, -5.7724e-01,  5.0252e-01,  5.2180e-01,\n",
       "         5.7327e-02, -7.9754e-01, -3.7770e-01,  7.8149e-01,  2.4597e-01,\n",
       "         6.0672e-01, -2.0082e-01, -3.8792e-01,  4.1295e-01, -1.6143e-01,\n",
       "         1.0427e-02,  4.3197e-01,  4.6297e-03,  2.1185e-01, -2.6606e-01,\n",
       "        -5.8740e-02, -5.1003e-01,  2.8524e-01,  1.3627e-02, -2.7346e-01,\n",
       "         6.1848e-02, -5.7901e-01, -5.1136e-01,  3.6382e-01,  3.5144e-01,\n",
       "        -1.6501e-01, -4.6041e-01, -6.4742e-02, -6.8310e-01, -4.7427e-02,\n",
       "         1.5861e-01, -4.7288e-01,  3.3968e-01,  1.2092e-03,  1.6018e-01,\n",
       "        -5.8024e-01,  1.4556e-01, -9.1317e-01, -3.7592e-01, -3.2950e-01,\n",
       "         5.3465e-01,  1.8224e-01, -5.2265e-01, -2.6209e-01, -4.2458e-01,\n",
       "        -1.8034e-01,  9.9502e-02, -1.5114e-01, -6.6731e-01,  2.4483e-01,\n",
       "        -5.6630e-01,  3.3843e-01,  4.0558e-01,  1.8073e-01,  6.4250e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k6/m9tg9pk53qx5dc10_wkhzm500000gn/T/ipykernel_69145/940565912.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
     ]
    }
   ],
   "source": [
    "print(glove.vectors.shape)\n",
    "print(type(glove.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/train.csv')\n",
    "sentences = df['text'].values\n",
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3345810\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "for sentence in sentences:\n",
    "    for word in tokenizer(sentence):\n",
    "        word_list.append(word)\n",
    "\n",
    "print(len(word_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56069\n"
     ]
    }
   ],
   "source": [
    "freq = Counter(word_list)\n",
    "freq_ = sorted(freq,key=freq.get,reverse=True)\n",
    "\n",
    "print(len(freq_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k6/m9tg9pk53qx5dc10_wkhzm500000gn/T/ipykernel_69145/3280326970.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'this'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m240000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
     ]
    }
   ],
   "source": [
    "glove.stoi['this']\n",
    "test = copy.deepcopy(glove.vectors[:240000])\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    '''\n",
    "    input_size -> text vocab size\n",
    "    '''\n",
    "    def __init__(self, input_size, output_size, embedding_dim, hidden_dim, num_layers, batch_first):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first   \n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        \"\"\"\n",
    "        TODO: Implement your own model. You can change the model architecture.\n",
    "        \"\"\"\n",
    "        # self.embedding = nn.Embedding.from_pretrained(test,freeze=True)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=batch_first)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    # the size of x in forward is (seq_length, batch_size) if batch_first=False\n",
    "    def forward(self, x, input_lengths):\n",
    "        batch_size = x.size(0) if self.batch_first else x.size(1)\n",
    "\n",
    "        #h_0: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "        c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "\n",
    "        embedding = self.embedding(x)\n",
    "        packed_input = pack_padded_sequence(embedding, input_lengths.tolist(), batch_first=self.batch_first)\n",
    "        # output, hidden = self.rnn(packed_input, (h_0, c_0))\n",
    "        packed_output, hidden = self.rnn(packed_input)\n",
    "        # output, _ = pad_packed_sequence(output, batch_first=self.batch_first)\n",
    "\n",
    "        output = self.fc(hidden[0][-1])\n",
    "\n",
    "        # outputs, hidden = self.rnn(embedding, None)  # outputs.shape -> (sequence length, batch size, hidden size)\n",
    "\n",
    "        # outputs = outputs[:, -1, :] if self.batch_first else outputs[-1, :, :]\n",
    "        # output = self.fc(outputs)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(240000, 2, 300, 64, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k6/m9tg9pk53qx5dc10_wkhzm500000gn/T/ipykernel_69145/889294483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LSTM_ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_ATTENTION(60000, 3, 300, 64, 3, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Test Loader\n",
    "test_dataset = TextDataset('./Data', 'test', 60000)\n",
    "test_loader = make_data_loader(test_dataset, 32, True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30])\n",
      "tensor([  981,    48,     7,  1077,    52,    11,   423,   147,    14,  3150,\n",
      "         2622,    52,  3299,  2384,     6,   181,    46,  5786,    48,  2157,\n",
      "        38821,   101, 13248,  3299,    17,  3490,   522,   644,    63,    22])\n",
      "torch.Size([685, 128])\n",
      "tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 30, 29, 29, 29, 27,\n",
      "        26, 23, 20, 17, 14, 10,  7,  4,  1,  1,  1,  1])\n",
      "tensor(685)\n",
      "torch.Size([30])\n",
      "--------------\n",
      "torch.Size([32, 2])\n",
      "torch.Size([6, 32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i,(text,label) in enumerate(tqdm(test_loader)):\n",
    "    input_lengths = torch.tensor([len(x.nonzero()) for x in text])\n",
    "    input_lengths, perm_idx = input_lengths.sort(0,descending=True)\n",
    "    text = text[perm_idx]\n",
    "    label = label[perm_idx]\n",
    "\n",
    "    output, hidden, pad = model(text, input_lengths)\n",
    "\n",
    "    print(text.shape)\n",
    "    print(text[0])\n",
    "    print(pad.data.shape)\n",
    "    print(pad.batch_sizes)\n",
    "    print(torch.sum(pad.batch_sizes))\n",
    "    print(pad.batch_sizes.shape)\n",
    "    print(\"--------------\")\n",
    "    print(output.shape)\n",
    "    print(hidden[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "0.032375626266002655\n",
      "0.03271143138408661\n"
     ]
    }
   ],
   "source": [
    "# print(hidden[0][0,0,0])\n",
    "# print(hidden[0][1,0,0])\n",
    "# print(hidden[0][2,0,0])\n",
    "# print(hidden[0][3,0,0])\n",
    "# print(hidden[0][4,0,0])\n",
    "# print(hidden[0][5,0,0].item())\n",
    "# print(pad.data[1][0].item())\n",
    "# print(pad[1][0])\n",
    "for i in range(685):\n",
    "    for j in range(6):    \n",
    "        if pad.data[i][64].item() == hidden[0][j,0,0].item():\n",
    "            print(i,j)\n",
    "            \n",
    "# print(pad.data[-1][:64])\n",
    "# print(hidden[0][4,0])\n",
    "\n",
    "print(pad.data[-1][63].item())\n",
    "print(hidden[0][5,0,0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "# concat hidden[0][-1] & hidden[0][-2]\n",
    "\n",
    "h = torch.concat((hidden[0][-2],hidden[0][-1]),1)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "26 26\n",
      "27 27\n",
      "28 28\n",
      "29 29\n",
      "30 30\n",
      "31 31\n",
      "32 32\n",
      "33 33\n",
      "34 34\n",
      "35 35\n",
      "36 36\n",
      "37 37\n",
      "38 38\n",
      "39 39\n",
      "40 40\n",
      "41 41\n",
      "42 42\n",
      "43 43\n",
      "44 44\n",
      "45 45\n",
      "46 46\n",
      "47 47\n",
      "48 48\n",
      "49 49\n",
      "50 50\n",
      "51 51\n",
      "52 52\n",
      "53 53\n",
      "54 54\n",
      "55 55\n",
      "56 56\n",
      "57 57\n",
      "58 58\n",
      "59 59\n",
      "60 60\n",
      "61 61\n",
      "62 62\n",
      "63 63\n"
     ]
    }
   ],
   "source": [
    "# print(h[0])\n",
    "# print(pad.data[684][64])\n",
    "for i in range(128):\n",
    "    for j in range(128):\n",
    "        if pad.data[684][i].item() == h[0][j].item():\n",
    "            print(i,j)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_output, packed_hidden = pad_packed_sequence(pad, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30, 128])\n"
     ]
    }
   ],
   "source": [
    "print(packed_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0089, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0089, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(packed_output[-1][0][0])\n",
    "print(hidden[0][4][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.zeros(packed_output.size(0),1).long()\n",
    "inp += 2\n",
    "print(inp)\n",
    "print(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(60000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = embedding(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 300])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(300,64,3,bidirectional=True,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,h = lstm(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = l.view(l.shape[0],l.shape[2],-1)\n",
    "a = torch.bmm(packed_output,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30, 1])\n",
      "torch.Size([32, 30, 128])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(packed_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_dis = F.softmax(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30, 1])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_dis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0335],\n",
       "        [0.0335],\n",
       "        [0.0336],\n",
       "        [0.0336],\n",
       "        [0.0335],\n",
       "        [0.0335],\n",
       "        [0.0335],\n",
       "        [0.0334],\n",
       "        [0.0333],\n",
       "        [0.0332],\n",
       "        [0.0332],\n",
       "        [0.0332],\n",
       "        [0.0331],\n",
       "        [0.0331],\n",
       "        [0.0331],\n",
       "        [0.0331],\n",
       "        [0.0332],\n",
       "        [0.0332],\n",
       "        [0.0332],\n",
       "        [0.0333],\n",
       "        [0.0333],\n",
       "        [0.0335],\n",
       "        [0.0335],\n",
       "        [0.0334],\n",
       "        [0.0335],\n",
       "        [0.0336],\n",
       "        [0.0335],\n",
       "        [0.0333],\n",
       "        [0.0331],\n",
       "        [0.0331]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_dis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_val = torch.sum(att_dis * packed_output,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0194, -0.0533, -0.0954, -0.0021,  0.0615,  0.0166, -0.0876, -0.0468,\n",
       "         0.0302,  0.0076, -0.0161,  0.0373, -0.0561,  0.0250, -0.0242, -0.0376,\n",
       "        -0.0156,  0.0522,  0.0137,  0.0154, -0.0069, -0.1210,  0.0198,  0.0825,\n",
       "         0.0373, -0.0346, -0.0512, -0.1070,  0.0046,  0.0510,  0.0707, -0.1055,\n",
       "        -0.0070,  0.0717,  0.0309, -0.0245,  0.0198, -0.0219, -0.0603, -0.0379,\n",
       "        -0.0213,  0.0248, -0.0282, -0.0646, -0.0268,  0.0162, -0.1221, -0.0987,\n",
       "         0.1353, -0.1139,  0.0329, -0.0816, -0.0916,  0.0314,  0.0149, -0.0383,\n",
       "         0.0366,  0.0169, -0.0181,  0.0241,  0.0574,  0.1169,  0.0767, -0.0011,\n",
       "         0.0021,  0.0433,  0.0403,  0.0765, -0.1053, -0.0378,  0.0569,  0.0192,\n",
       "         0.0573, -0.0308,  0.0897,  0.0808,  0.0734,  0.0504, -0.0058, -0.0012,\n",
       "        -0.0667, -0.0833,  0.0385, -0.0872,  0.0181, -0.0853,  0.0447,  0.0739,\n",
       "         0.0485,  0.0676, -0.0354,  0.0121,  0.0255,  0.0235,  0.0017, -0.0419,\n",
       "         0.0870, -0.0318, -0.1115,  0.0236, -0.0652,  0.0454,  0.0100, -0.0032,\n",
       "        -0.0217,  0.0386,  0.0161, -0.0282,  0.0003, -0.1303,  0.0326,  0.0185,\n",
       "        -0.0560, -0.0508, -0.0054, -0.0650, -0.0667, -0.0159,  0.0047, -0.0315,\n",
       "         0.0040,  0.0295,  0.0620, -0.0848, -0.0024, -0.0506,  0.0385, -0.0636],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = att_dis * packed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30, 128])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(att_dis,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = torch.cat((att_val,l.squeeze(2)),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256])\n"
     ]
    }
   ],
   "source": [
    "print(con.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "print(l.squeeze(2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99e55bba2bfd190bfffb28d55de7b9b9d0506f838e465f2cacf9c84476e1bc53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
