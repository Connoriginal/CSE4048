{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils import rnn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "# from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vectors,GloVe\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:44, 5.24MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [01:08<00:00, 5829.78it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 30000\n",
    "glove = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.vocab.vectors.GloVe'>\n"
     ]
    }
   ],
   "source": [
    "print(type(glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.3712e-01, -2.1691e-01, -6.6365e-03, -4.1625e-01, -1.2555e+00,\n",
       "        -2.8466e-02, -7.2195e-01, -5.2887e-01,  7.2085e-03,  3.1997e-01,\n",
       "         2.9425e-02, -1.3236e-02,  4.3511e-01,  2.5716e-01,  3.8995e-01,\n",
       "        -1.1968e-01,  1.5035e-01,  4.4762e-01,  2.8407e-01,  4.9339e-01,\n",
       "         6.2826e-01,  2.2888e-01, -4.0385e-01,  2.7364e-02,  7.3679e-03,\n",
       "         1.3995e-01,  2.3346e-01,  6.8122e-02,  4.8422e-01, -1.9578e-02,\n",
       "        -5.4751e-01, -5.4983e-01, -3.4091e-02,  8.0017e-03, -4.3065e-01,\n",
       "        -1.8969e-02, -8.5670e-02, -8.1123e-01, -2.1080e-01,  3.7784e-01,\n",
       "        -3.5046e-01,  1.3684e-01, -5.5661e-01,  1.6835e-01, -2.2952e-01,\n",
       "        -1.6184e-01,  6.7345e-01, -4.6597e-01, -3.1834e-02, -2.6037e-01,\n",
       "        -1.7797e-01,  1.9436e-02,  1.0727e-01,  6.6534e-01, -3.4836e-01,\n",
       "         4.7833e-02,  1.6440e-01,  1.4088e-01,  1.9204e-01, -3.5009e-01,\n",
       "         2.6236e-01,  1.7626e-01, -3.1367e-01,  1.1709e-01,  2.0378e-01,\n",
       "         6.1775e-01,  4.9075e-01, -7.5210e-02, -1.1815e-01,  1.8685e-01,\n",
       "         4.0679e-01,  2.8319e-01, -1.6290e-01,  3.8388e-02,  4.3794e-01,\n",
       "         8.8224e-02,  5.9046e-01, -5.3515e-02,  3.8819e-02,  1.8202e-01,\n",
       "        -2.7599e-01,  3.9474e-01, -2.0499e-01,  1.7411e-01,  1.0315e-01,\n",
       "         2.5117e-01, -3.6542e-01,  3.6528e-01,  2.2448e-01, -9.7551e-01,\n",
       "         9.4505e-02, -1.7859e-01, -3.0688e-01, -5.8633e-01, -1.8526e-01,\n",
       "         3.9565e-02, -4.2309e-01, -1.5715e-01,  2.0401e-01,  1.6906e-01,\n",
       "         3.4465e-01, -4.2262e-01,  1.9553e-01,  5.9454e-01, -3.0531e-01,\n",
       "        -1.0633e-01, -1.9055e-01, -5.8544e-01,  2.1357e-01,  3.8414e-01,\n",
       "         9.1499e-02,  3.8353e-01,  2.9075e-01,  2.4519e-02,  2.8440e-01,\n",
       "         6.3715e-02, -1.5483e-01,  4.0031e-01,  3.1543e-01, -3.7128e-02,\n",
       "         6.3363e-02, -2.7090e-01,  2.5160e-01,  4.7105e-01,  4.9556e-01,\n",
       "        -3.6401e-01,  1.0370e-01,  4.6076e-02,  1.6565e-01, -2.9024e-01,\n",
       "        -6.6949e-02, -3.0881e-01,  4.8263e-01,  3.0972e-01, -1.1145e-01,\n",
       "        -1.0329e-01,  2.8585e-02, -1.3579e-01,  5.2924e-01, -1.4077e-01,\n",
       "         9.1763e-02,  1.3127e-01, -2.0944e-01,  2.2327e-02, -7.7692e-02,\n",
       "         7.7934e-02, -3.3067e-02,  1.1680e-01,  3.2029e-01,  3.7749e-01,\n",
       "        -7.5679e-01, -1.5944e-01,  1.4964e-01,  4.2253e-01,  2.8136e-03,\n",
       "         2.1328e-01,  8.6776e-02, -5.2704e-02, -4.0859e-01, -1.1774e-01,\n",
       "         9.0621e-02, -2.3794e-01, -1.8326e-01,  1.3115e-01, -5.5949e-01,\n",
       "         9.2071e-02, -3.9504e-02,  1.3334e-01,  4.9632e-01,  2.8733e-01,\n",
       "        -1.8544e-01,  2.4618e-02, -4.2826e-01,  7.4148e-02,  7.6584e-04,\n",
       "         2.3950e-01,  2.2615e-01,  5.5166e-02, -7.5096e-02, -2.2308e-01,\n",
       "         2.3775e-01, -4.5455e-01,  2.6564e-01, -1.5137e-01, -2.4146e-01,\n",
       "        -2.4736e-01,  5.5214e-01,  2.6819e-01,  4.8831e-01, -1.3423e-01,\n",
       "        -1.5918e-01,  3.7606e-01, -1.9834e-01,  1.6699e-01, -1.5368e-01,\n",
       "         2.4561e-01, -9.2506e-02, -3.0257e-01, -2.9493e-01, -7.4917e-01,\n",
       "         1.0567e+00,  3.7971e-01,  6.9314e-01, -3.1672e-02,  2.1588e-01,\n",
       "        -4.0739e-01, -1.5264e-01,  3.2296e-01, -1.2999e-01, -5.0129e-01,\n",
       "        -4.4231e-01,  1.6904e-02, -1.1459e-02,  7.2293e-03,  1.1026e-01,\n",
       "         2.1568e-01, -3.2373e-01, -3.7292e-01, -9.2456e-03, -2.6769e-01,\n",
       "         3.9066e-01,  3.5742e-01, -6.0632e-02,  6.7966e-02,  3.3830e-01,\n",
       "         6.5747e-02,  1.5794e-01,  4.7155e-02,  2.3682e-01, -9.1370e-02,\n",
       "         6.4649e-01, -2.5491e-01, -6.7940e-01, -6.9752e-01, -1.0145e-01,\n",
       "        -3.6255e-01,  3.6967e-01, -4.1295e-01,  8.2724e-02, -3.5053e-01,\n",
       "        -1.7564e-01,  8.5095e-02, -5.7724e-01,  5.0252e-01,  5.2180e-01,\n",
       "         5.7327e-02, -7.9754e-01, -3.7770e-01,  7.8149e-01,  2.4597e-01,\n",
       "         6.0672e-01, -2.0082e-01, -3.8792e-01,  4.1295e-01, -1.6143e-01,\n",
       "         1.0427e-02,  4.3197e-01,  4.6297e-03,  2.1185e-01, -2.6606e-01,\n",
       "        -5.8740e-02, -5.1003e-01,  2.8524e-01,  1.3627e-02, -2.7346e-01,\n",
       "         6.1848e-02, -5.7901e-01, -5.1136e-01,  3.6382e-01,  3.5144e-01,\n",
       "        -1.6501e-01, -4.6041e-01, -6.4742e-02, -6.8310e-01, -4.7427e-02,\n",
       "         1.5861e-01, -4.7288e-01,  3.3968e-01,  1.2092e-03,  1.6018e-01,\n",
       "        -5.8024e-01,  1.4556e-01, -9.1317e-01, -3.7592e-01, -3.2950e-01,\n",
       "         5.3465e-01,  1.8224e-01, -5.2265e-01, -2.6209e-01, -4.2458e-01,\n",
       "        -1.8034e-01,  9.9502e-02, -1.5114e-01, -6.6731e-01,  2.4483e-01,\n",
       "        -5.6630e-01,  3.3843e-01,  4.0558e-01,  1.8073e-01,  6.4250e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400000, 300])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(glove.vectors.shape)\n",
    "print(type(glove.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/train.csv')\n",
    "sentences = df['text'].values\n",
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3345810\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "for sentence in sentences:\n",
    "    for word in tokenizer(sentence):\n",
    "        word_list.append(word)\n",
    "\n",
    "print(len(word_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56069\n"
     ]
    }
   ],
   "source": [
    "freq = Counter(word_list)\n",
    "freq_ = sorted(freq,key=freq.get,reverse=True)\n",
    "\n",
    "print(len(freq_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240000, 300])\n"
     ]
    }
   ],
   "source": [
    "glove.stoi['this']\n",
    "test = copy.deepcopy(glove.vectors[:240000])\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    '''\n",
    "    input_size -> text vocab size\n",
    "    '''\n",
    "    def __init__(self, input_size, output_size, embedding_dim, hidden_dim, num_layers, batch_first):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first   \n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        \"\"\"\n",
    "        TODO: Implement your own model. You can change the model architecture.\n",
    "        \"\"\"\n",
    "        # self.embedding = nn.Embedding.from_pretrained(test,freeze=True)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=batch_first)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    # the size of x in forward is (seq_length, batch_size) if batch_first=False\n",
    "    def forward(self, x, input_lengths):\n",
    "        batch_size = x.size(0) if self.batch_first else x.size(1)\n",
    "\n",
    "        #h_0: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "        c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "\n",
    "        embedding = self.embedding(x)\n",
    "        packed_input = pack_padded_sequence(embedding, input_lengths.tolist(), batch_first=self.batch_first)\n",
    "        # output, hidden = self.rnn(packed_input, (h_0, c_0))\n",
    "        packed_output, hidden = self.rnn(packed_input)\n",
    "        # output, _ = pad_packed_sequence(output, batch_first=self.batch_first)\n",
    "\n",
    "        output = self.fc(hidden[0][-1])\n",
    "\n",
    "        # outputs, hidden = self.rnn(embedding, None)  # outputs.shape -> (sequence length, batch size, hidden size)\n",
    "\n",
    "        # outputs = outputs[:, -1, :] if self.batch_first else outputs[-1, :, :]\n",
    "        # output = self.fc(outputs)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(240000, 2, 300, 64, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
       "        [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n",
       "        [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
       "        ...,\n",
       "        [ 0.2044, -0.2027, -0.1458,  ...,  0.8147,  0.0636,  0.4498],\n",
       "        [-0.3197, -0.7546,  0.7908,  ...,  0.1304, -0.1798, -0.1267],\n",
       "        [ 1.0571,  0.1381,  0.1052,  ...,  0.0510,  0.6684, -0.6450]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99e55bba2bfd190bfffb28d55de7b9b9d0506f838e465f2cacf9c84476e1bc53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
