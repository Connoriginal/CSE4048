{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0be1f82",
   "metadata": {},
   "source": [
    "# Building NNs using PyTorch\n",
    "---\n",
    "## 목차\n",
    "1. [torch.Tensor](#torch.Tensor)\n",
    "2. [Tensor operations](#Tensor-operations)\n",
    "3. [Autograd](#Autograd)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e5cdc",
   "metadata": {},
   "source": [
    "## torch.Tensor\n",
    "\n",
    "* Like tensors in linear algebra, PyTorch tensors are arrays which can be multi-dimensional\n",
    "* PyTorch tensors are similarto NumPy ndarrays except for GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d6c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a04384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[1 2]\n",
      " [2 3]]\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[1., 2.],\n",
      "        [2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize with Python lists\n",
    "arr = [[1,2],[2,3]]\n",
    "\n",
    "arr_n = np.array(arr)\n",
    "print(type(arr_n))\n",
    "print(arr_n)\n",
    "\n",
    "arr_t = torch.Tensor(arr)\n",
    "print(type(arr_t))\n",
    "print(arr_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75623cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "[[0 0]\n",
      " [0 0]]\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Initialization : ones& zeros\n",
    "print(np.ones((2,3)))\n",
    "print(np.zeros((2,3)))\n",
    "print(torch.ones((2,3)))\n",
    "print(torch.zeros((2,3)))\n",
    "\n",
    "# Initialization : ones_like & zeros_like\n",
    "print(np.ones_like(arr_n))\n",
    "print(np.zeros_like(arr_n))\n",
    "print(torch.ones_like(arr_t))\n",
    "print(torch.zeros_like(arr_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24334e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways of specifying data type\n",
    "\n",
    "## 1. Use keyword argument dtype\n",
    "print(torch.ones((2,3),dtype = torch.int))\n",
    "print(torch.ones((2,3),dtype = torch.float))\n",
    "\n",
    "## 2. Use typed tensors\n",
    "ft = torch.FloatTensor([1,2])\n",
    "print(ft)\n",
    "print(ft.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace18c2",
   "metadata": {},
   "source": [
    "## Tensor operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4801086",
   "metadata": {},
   "source": [
    "### Accessing elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbaf54b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "2.0\n",
      "tensor([[1., 0.],\n",
      "        [2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements\n",
    "\n",
    "## Access is similar to NumPy but it always returns Tensor\n",
    "arr_t = torch.Tensor([[1,2],[2,3]])\n",
    "print(arr_t[0,1])\n",
    "\n",
    "## Get a Python Number\n",
    "print(arr_t[0,1].item())\n",
    "\n",
    "## Update is same with NumPy\n",
    "arr_t[0,1] = 0\n",
    "print(arr_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4649569c",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d437e7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [2., 3., 4., 5.],\n",
      "        [5., 6., 7., 8.]])\n",
      "t[:2] = tensor([[1., 2., 3., 4.],\n",
      "        [2., 3., 4., 5.]])\n",
      "t[:,1:] = tensor([[2., 3., 4.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "t[1:,1:3] = tensor([[3., 4.],\n",
      "        [6., 7.]])\n",
      "t[:,:-1] = tensor([[1., 2., 3.],\n",
      "        [2., 3., 4.],\n",
      "        [5., 6., 7.]])\n",
      "t[:,-3:-1] = tensor([[2., 3.],\n",
      "        [3., 4.],\n",
      "        [6., 7.]])\n",
      "---------------------------------\n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [2., 0., 0., 5.],\n",
      "        [5., 0., 0., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "\n",
    "t = torch.Tensor([[1,2,3,4],[2,3,4,5],[5,6,7,8]])\n",
    "print(t)\n",
    "\n",
    "print(f\"t[:2] = {t[:2]}\")\n",
    "print(f\"t[:,1:] = {t[:,1:]}\")\n",
    "print(f\"t[1:,1:3] = {t[1:,1:3]}\")\n",
    "print(f\"t[:,:-1] = {t[:,:-1]}\")\n",
    "print(f\"t[:,-3:-1] = {t[:,-3:-1]}\")\n",
    "print(\"---------------------------------\")\n",
    "t[1:,1:3] = 0\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3eeb29",
   "metadata": {},
   "source": [
    "### Shape & Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36e4ae1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Shape & Transpose\n",
    "\n",
    "## Transpose of 2-D tensor(matrix)\n",
    "X = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "print(X.shape)\n",
    "print(X.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230c0ae",
   "metadata": {},
   "source": [
    "### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "437bea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([5., 7., 9.])\n",
      "tensor([ 6., 15.])\n",
      "tensor([[5., 7., 9.]])\n",
      "tensor([[ 6.],\n",
      "        [15.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.sum(input, dim, keepdim = False, *,dtype = None)\n",
    "## dim : 0 -> col, 1 -> row\n",
    "## keepdim : True / False \n",
    "print(X)\n",
    "print(X.sum(0))\n",
    "print(X.sum(1))\n",
    "print(X.sum(0,keepdim=True))\n",
    "print(X.sum(1,keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13822d",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf152c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor(3.5000)\n",
      "tensor([2.5000, 3.5000, 4.5000])\n",
      "tensor([2., 5.])\n"
     ]
    }
   ],
   "source": [
    "#torch.mean(input,dim,keepdim=False,*)\n",
    "print(X)\n",
    "print(X.mean())\n",
    "print(X.mean(0))\n",
    "print(X.mean(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f710bb4",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37efdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor(6.)\n",
      "torch.return_types.max(\n",
      "values=tensor([4., 5., 6.]),\n",
      "indices=tensor([1, 1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 6.]),\n",
      "indices=tensor([2, 2]))\n"
     ]
    }
   ],
   "source": [
    "# torch.max(input, dim, keepdim=False)\n",
    "print(X)\n",
    "print(X.max())\n",
    "print(X.max(0))\n",
    "print(X.max(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eff8fd",
   "metadata": {},
   "source": [
    "### Binary Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "783e09f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 5.],\n",
      "        [5., 5., 7.]])\n",
      "tensor([[1., 0., 6.],\n",
      "        [4., 0., 6.]])\n",
      "tensor([[ 5.,  0.,  6.],\n",
      "        [ 7.,  0.,  9.],\n",
      "        [ 9.,  0., 12.]])\n",
      "tensor([[ 7.,  4.],\n",
      "        [16., 10.]])\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "Y = torch.Tensor([[1,0,2],[1,0,1]])\n",
    "x = torch.FloatTensor([1,2])\n",
    "y = torch.FloatTensor([1,1])\n",
    "\n",
    "# Addition\n",
    "print(X+Y)\n",
    "\n",
    "# Element-wise multiplication\n",
    "print(X*Y)\n",
    "\n",
    "# Matrix Multiplication\n",
    "print(torch.matmul(X.T,Y))\n",
    "print(torch.matmul(X,Y.T))\n",
    "\n",
    "# inner product (내적)\n",
    "print(torch.inner(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53870b",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29410e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape : torch.Size([2, 3, 3])\n",
      "tensor([[[1., 3., 1.],\n",
      "         [0., 2., 1.],\n",
      "         [1., 2., 5.]],\n",
      "\n",
      "        [[0., 4., 2.],\n",
      "         [1., 1., 2.],\n",
      "         [3., 2., 1.]]])\n",
      "-------------\n",
      "Y.shape : torch.Size([3, 2, 3])\n",
      "tensor([[[1., 3., 1.],\n",
      "         [0., 2., 1.]],\n",
      "\n",
      "        [[1., 2., 5.],\n",
      "         [0., 4., 2.]],\n",
      "\n",
      "        [[1., 1., 2.],\n",
      "         [3., 2., 1.]]])\n",
      "-------------\n",
      "Z.shape : torch.Size([6, 3])\n",
      "tensor([[1., 3., 1.],\n",
      "        [0., 2., 1.],\n",
      "        [1., 2., 5.],\n",
      "        [0., 4., 2.],\n",
      "        [1., 1., 2.],\n",
      "        [3., 2., 1.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([[[1,3,1],[0,2,1],[1,2,5]],[[0,4,2],[1,1,2],[3,2,1]]])\n",
    "\n",
    "print(f\"X.shape : {X.shape}\")\n",
    "print(X)\n",
    "print(\"-------------\")\n",
    "\n",
    "Y = X.view(3,2,3)\n",
    "print(f\"Y.shape : {Y.shape}\")\n",
    "print(Y)\n",
    "print(\"-------------\")\n",
    "\n",
    "Z = X.view(6,3)\n",
    "print(f\"Z.shape : {Z.shape}\")\n",
    "print(Z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249a6ecd",
   "metadata": {},
   "source": [
    "### Squeeze & Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0e07e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([[[1,2,3]],[[4,5,6]],[[7,8,9]],[[10,11,12]]])\n",
    "print(X.shape)\n",
    "Y = X.squeeze(dim=1)\n",
    "print(Y.shape)\n",
    "Z = Y.unsqueeze(dim=1)\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19584c8a",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01c041f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape : torch.Size([2, 3, 3])\n",
      "tensor([[[1., 3., 1.],\n",
      "         [0., 2., 1.],\n",
      "         [1., 2., 5.]],\n",
      "\n",
      "        [[0., 4., 2.],\n",
      "         [1., 1., 2.],\n",
      "         [3., 2., 1.]]])\n",
      "tensor([[[2., 4., 2.],\n",
      "         [1., 3., 2.],\n",
      "         [2., 3., 6.]],\n",
      "\n",
      "        [[1., 5., 3.],\n",
      "         [2., 2., 3.],\n",
      "         [4., 3., 2.]]])\n",
      "tensor([[[2., 4., 2.],\n",
      "         [1., 3., 2.],\n",
      "         [2., 3., 6.]],\n",
      "\n",
      "        [[1., 5., 3.],\n",
      "         [2., 2., 3.],\n",
      "         [4., 3., 2.]]])\n",
      "tensor([[[2., 4., 2.],\n",
      "         [1., 3., 2.],\n",
      "         [2., 3., 6.]],\n",
      "\n",
      "        [[1., 5., 3.],\n",
      "         [2., 2., 3.],\n",
      "         [4., 3., 2.]]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([[[1,3,1],[0,2,1],[1,2,5]],[[0,4,2],[1,1,2],[3,2,1]]])\n",
    "\n",
    "print(f\"X.shape : {X.shape}\")\n",
    "print(X)\n",
    "\n",
    "Y1 = torch.ones((1,1,3))\n",
    "Y2 = torch.ones((1,3))\n",
    "Y3 = torch.ones(3)\n",
    "\n",
    "print(X+Y1)\n",
    "print(X+Y2)\n",
    "print(X+Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fbf25",
   "metadata": {},
   "source": [
    "### ndarray <-> tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9014c1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "tensor([1, 2, 3])\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "print(a)\n",
    "t = torch.from_numpy(a)\n",
    "t1 = torch.from_numpy(a)\n",
    "print(t)\n",
    "c = t.numpy()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac204a6",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "* torch.autograd is PyTorch's <b>automatic differentiation engine</b> that powers neural network training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5749bcda",
   "metadata": {},
   "source": [
    "1. initialization\n",
    "> set requires_grad to True if you want to track the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc3cb5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w True\n",
      "x False\n",
      "<torch.autograd.grad_mode.no_grad object at 0x7fce365b2bb0>\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(2,requires_grad = True)\n",
    "x = torch.ones(2)\n",
    "print(\"w\",w.requires_grad)\n",
    "print(\"x\",x.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24325851",
   "metadata": {},
   "source": [
    "2. backward()\n",
    "> Computes the sum of gradients of given tensors w.r.t. the leaves of computation graphs\n",
    "* Accessing the gradient\n",
    "> w.grad : w is a tensor whose requires_grad is True\n",
    "\n",
    "* Torch.no_grad\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    w = w - lr * w.grad\n",
    "```\n",
    "> Torch.no_grad disables gradient calculation\n",
    "\n",
    "3. in-place operations and Autograd\n",
    "> An in-place operation is an operation that changes <b>directly the content of a given Tensor</b> without making a copy\n",
    "> > <b> Anyway, never use in-place operation to the tensors on the path from the parameters to the loss</b>\n",
    "\n",
    "- in-place operations\n",
    "```python\n",
    "A += X\n",
    "a[i:] = 0\n",
    "```\n",
    "- Without in-place operations\n",
    "```python\n",
    "A = A + X\n",
    "mask = torch.ones_like(a)\n",
    "mask[i:] = 0\n",
    "a = a*mask\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d75361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
