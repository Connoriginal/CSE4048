{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54f2c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a9a5d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "tensor(20.)\n",
      "tensor(20.)\n",
      "tensor(20.)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.Tensor([1,2,3,4])\n",
    "print(x1.shape)\n",
    "x2 = torch.Tensor([4,3,2,1])\n",
    "print(x2.shape)\n",
    "\n",
    "print(torch.matmul(x1,x2))\n",
    "print(torch.inner(x1,x2))\n",
    "print(torch.dot(x1,x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d886fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "w shape : torch.Size([2]) , x.shape : torch.Size([2])\n",
      "requires grad , w : True, x : False\n",
      "w is tensor([ 1.2726, -0.5472], requires_grad=True)\n",
      "x is tensor([1., 2.]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Autograd example\n",
    "## Initialization\n",
    "w = torch.randn(2,requires_grad=True)\n",
    "x = torch.Tensor([1,2])\n",
    "print(f'''\n",
    "w shape : {w.shape} , x.shape : {x.shape}\n",
    "requires grad , w : {w.requires_grad}, x : {x.requires_grad}\n",
    "w is {w}\n",
    "x is {x} \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a95450f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 1.747126579284668\n",
      "\n",
      "w is tensor([ 1.2726, -0.5472], requires_grad=True)\n",
      "x is tensor([1., 2.])\n",
      "yhat is 0.17821085453033447\n",
      "gradient of w is tensor([-2.6436, -5.2872])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict output\n",
    "yhat = torch.inner(w,x)\n",
    "# Compute loss (L2 squared Error)\n",
    "loss = (x.mean() - yhat)**2\n",
    "print(f\"loss : {loss}\")\n",
    "#backpropagation\n",
    "loss.backward()\n",
    "# Intermediate results\n",
    "print(f'''\n",
    "w is {w}\n",
    "x is {x}\n",
    "yhat is {yhat}\n",
    "gradient of w is {w.grad}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "228003ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "w.requires_grad : False\n",
      "w is tensor([0.8136, 0.3432])\n",
      "w.grad is None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update parameters\n",
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    w = w - lr*w.grad\n",
    "print(f'''\n",
    "w.requires_grad : {w.requires_grad}\n",
    "w is {w}\n",
    "w.grad is {w.grad}\n",
    "''')\n",
    "w.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8784c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inplace operation\n",
      "w.requires_grad : True\n",
      "w is tensor([ 1.5370, -0.0185], requires_grad=True)\n",
      "w.grad is tensor([-2.6436, -5.2872])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update parameters\n",
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    w -= lr*w.grad\n",
    "print(f'''\n",
    "Inplace operation\n",
    "w.requires_grad : {w.requires_grad}\n",
    "w is {w}\n",
    "w.grad is {w.grad}\n",
    "''')\n",
    "w.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3635901a",
   "metadata": {},
   "source": [
    "# Model 관련 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "323ac6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "x_seeds = np.array([(0,0),(1,0),(0,1),(1,1)],dtype=np.float32)\n",
    "y_seeds = np.array([0,1,1,0])\n",
    "\n",
    "N = 1000\n",
    "idxs = np.random.randint(0,4,N)\n",
    "X = x_seeds[idxs]\n",
    "Y = y_seeds[idxs]\n",
    "X += np.random.normal(scale=0.25,size=X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "548b7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pytorch\n",
    "class pyt_shallow_nn():\n",
    "    def __init__(self,num_input,num_hiddens):\n",
    "        self.num_input = num_input\n",
    "        self.num_hiddens = num_hiddens\n",
    "        \n",
    "        self.W1 = torch.randn((self.num_hiddens, self.num_input),requires_grad=True)\n",
    "        self.b1 = torch.randn(self.num_hiddens, requires_grad=True)\n",
    "        self.w2 = torch.randn(self.num_hiddens, requires_grad=True)\n",
    "        self.b2 = torch.randn(1, requires_grad=True)\n",
    "        \n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        z1 = torch.matmul(self.W1,x) + self.b1\n",
    "        a1 = self.tanh(z1)\n",
    "        z2 = torch.inner(self.w2,a1) + self.b2 # Vector 에서는 matmul, inner , dot 동일\n",
    "        a2 = self.sigmoid(z2)\n",
    "        return a2, (z1,a1,z2,a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24d159ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703167968571186\n",
      "0.542680909126997\n",
      "0.40984806953370573\n",
      "0.3309936699979007\n",
      "0.28382578406482933\n",
      "0.2534042961001396\n",
      "0.23116889131627977\n",
      "0.2122963788304478\n",
      "0.19556920563802124\n",
      "0.1820383599512279\n"
     ]
    }
   ],
   "source": [
    "lr = 1.0\n",
    "m = len(X)\n",
    "model = pyt_shallow_nn(2,4)\n",
    "for epoch in range(100):\n",
    "    cost = 0.0\n",
    "    for x,y in zip(X,Y) :\n",
    "        x_torch = torch.from_numpy(x)\n",
    "        yhat,_ = model.forward(x_torch)\n",
    "        loss = -y*torch.log(yhat+0.0001) - (1-y)*torch.log(1-yhat+0.0001)\n",
    "        loss.backward()\n",
    "        cost += loss.item()\n",
    "    with torch.no_grad():\n",
    "        model.W1 = model.W1 - lr*model.W1.grad/m\n",
    "        model.b1 = model.b1 - lr*model.b1.grad/m\n",
    "        model.w2 = model.w2 - lr*model.w2.grad/m\n",
    "        model.b2 = model.b2 - lr*model.b2.grad/m\n",
    "    model.W1.requires_grad = True\n",
    "    model.b1.requires_grad = True\n",
    "    model.w2.requires_grad = True\n",
    "    model.b2.requires_grad = True\n",
    "    cost /= m\n",
    "    if epoch % 10 == 0:\n",
    "        print(cost)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b2e6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.module 활용\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self,in_features,out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_features,out_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return (input @ self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44025e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2266,  2.4446, -1.1795], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MyLinear(4,3)\n",
    "sample_input = torch.randn(4)\n",
    "m(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e52cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shallow_neural_network(nn.Module):\n",
    "    def __init__(self, num_input,num_hiddens):\n",
    "        super().__init__()\n",
    "        self.num_input = num_input\n",
    "        self.num_hiddens = num_hiddens\n",
    "        \n",
    "        self.layer1 = nn.Linear(self.num_input,self.num_hiddens)\n",
    "        self.layer2 = nn.Linear(self.num_hiddens,1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        z1 = self.layer1(x)\n",
    "        a1 = self.tanh(z1)\n",
    "        z2 = self.layer2(a1)\n",
    "        a2 = self.sigmoid(z2)\n",
    "        return a2,(z1,a1,z2,a2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "365691c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.6941, grad_fn=<DivBackward0>)\n",
      "10 tensor(0.6838, grad_fn=<DivBackward0>)\n",
      "20 tensor(0.6672, grad_fn=<DivBackward0>)\n",
      "30 tensor(0.6431, grad_fn=<DivBackward0>)\n",
      "40 tensor(0.6152, grad_fn=<DivBackward0>)\n",
      "50 tensor(0.5841, grad_fn=<DivBackward0>)\n",
      "60 tensor(0.5437, grad_fn=<DivBackward0>)\n",
      "70 tensor(0.4817, grad_fn=<DivBackward0>)\n",
      "80 tensor(0.4026, grad_fn=<DivBackward0>)\n",
      "90 tensor(0.3305, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "num_epoch = 100\n",
    "lr = 1.0\n",
    "\n",
    "model = shallow_neural_network(2,3)\n",
    "optimizer = optim.SGD(model.parameters(),lr = lr)\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    cost = 0.0\n",
    "    for x,y in zip(X,Y):\n",
    "        x_torch = torch.from_numpy(x)\n",
    "        y_torch = torch.FloatTensor([y])\n",
    "        \n",
    "        yhat,_ = model(x_torch)\n",
    "        \n",
    "        loss_val = loss(yhat,y_torch)\n",
    "        cost += loss_val\n",
    "    cost = cost/len(X)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if(epoch % 10 == 0):\n",
    "        print(epoch,cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33277fe2",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b06c74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "batch_size = 16\n",
    "\n",
    "train_data = datasets.MNIST('./datasets',train=True,download=True,transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('./datasets',train=False,download=True,transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08f83bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_dim = 28*28 #MNIST\n",
    "        self.out_dim = 10\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.in_dim,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,128)\n",
    "        self.fc4 = nn.Linear(128,64)\n",
    "        self.fc5 = nn.Linear(64,self.out_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        a1 = self.relu(self.fc1(x.view(-1,self.in_dim)))\n",
    "        a2 = self.relu(self.fc2(a1))\n",
    "        a3 = self.relu(self.fc3(a2))\n",
    "        a4 = self.relu(self.fc4(a3))\n",
    "        logit = self.relu(self.fc5(a4))\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e190b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a467d370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss : 2.287\n",
      "[2,  2000] loss : 1.282\n",
      "[3,  2000] loss : 1.095\n",
      "[4,  2000] loss : 1.036\n",
      "[5,  2000] loss : 1.007\n",
      "[6,  2000] loss : 0.988\n",
      "[7,  2000] loss : 0.979\n",
      "[8,  2000] loss : 0.768\n",
      "[9,  2000] loss : 0.739\n",
      "[10,  2000] loss : 0.735\n",
      "[11,  2000] loss : 0.721\n",
      "[12,  2000] loss : 0.716\n",
      "[13,  2000] loss : 0.709\n",
      "[14,  2000] loss : 0.711\n",
      "[15,  2000] loss : 0.698\n",
      "[16,  2000] loss : 0.694\n",
      "[17,  2000] loss : 0.695\n",
      "[18,  2000] loss : 0.690\n",
      "[19,  2000] loss : 0.691\n",
      "[20,  2000] loss : 0.696\n",
      "finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        yhat = model(inputs)\n",
    "        \n",
    "        loss = criterion(yhat,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if(i+1)%2000 == 0:\n",
    "            print(\"[%d, %5d] loss : %.3f\"%(epoch+1,i+1,running_loss/2000))\n",
    "            running_loss = 0\n",
    "\n",
    "print('finished Training')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e17e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    print(f\"npimg.shape : {npimg.shape}\")\n",
    "    np_trans = np.transpose(npimg,(1,2,0))\n",
    "    print(f\"np_trans.shape : {np_trans.shape}\")\n",
    "    plt.imshow(np_trans)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd854caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npimg.shape : (3, 32, 482)\n",
      "np_trans.shape : (32, 482, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAA5CAYAAAAvOXAvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAd/UlEQVR4nO2dd1hUV/rHv2cKMDp0EEchgFJExY5kEykWVFSibiRr3aySNYmPG40oqyZLMJZYoiRrEmtibCto1JBALDG6kg0SiiiCBURQaQIiw4BSZnh/f1B+KCjTgiGcz/O8z8ycO/e957733Pee8p5zGRGBw+FwOB0PwfPOAIfD4XC0gztwDofD6aBwB87hcDgdFO7AORwOp4PCHTiHw+F0ULgD53A4nA6KTg6cMTaeMXaDMXaTMbZcX5nicDgcTtswbePAGWNCABkA/ADkAkgEMIOIruovexwOh8N5GrrUwIcDuElEt4ioBkAEgMn6yRaHw+Fw2kIXB94TwN1mv3Mb0jgcDofTDoh02Je1ktaiP4YxNh/A/IafQ3U4HofD4XRWSojI+slEXRx4LgC7Zr9tAeQ/+Sci2glgJwAwxvjCKxwOh6M5t1tL1MWBJwJwZow5AsgDMB3ATB30/Sa4urrCysoKzs7OqKmpQVpaGtLS0lBXV/e8s8bhdAiGDRuG/v37IzY2Frdu3Xre2eE0Q2sHTkRKxthCAKcACAF8RUTpesuZHvD29sbatWvRvXt3yGQyqFQqpKSkYPbs2cjNzdXbcZydnTF37lyEh4ejuLhYaz1du3bF0qVLIZPJ8OGHHyI/v0WDRiOEQiFUKlWLdMYY9LUKpVAoBBFp/UAUCOqHYTraA1UoFMLCwgJmZmaora2FjY0NJBIJ0tPTdSoDumJjY4Pa2lr07t0bI0eOxO3bt1FQUICEhARUVVVprM/FxQXr1q2Dk5MTgoKCOoQDFwqFEAgETeVS17Ll4+ODefPmYfv27bhw4YLWegQCAQQCASwsLDB27Fj4+fnB2NgYcrkcV69excGDBzW/54mo3QT1feTtIv3796dr165RaWkpnTx5ksLCwuibb76hyspKeuONN/R6rNmzZ9PRo0fJwsJCax0CgYBGjhxJCoWCqqqqaMaMGTrlyczMjD7//HPq2bPnY+lCoZAmTpxINjY2Op+3nZ0dxcTE0Jo1a0ggEGi8v7W1NW3evJn+9a9/UdeuXVu1iZ+fH40YMUJj/cbGxtS3b18SiUR6u84ikYjs7e1pypQptHPnTsrKyqLy8nIqKSmh3NxcUigUtH79er2WLU3Ey8uLrly5Qvn5+XT37l0qLCyk3NxcKioqopSUFPLx8dHIjiKRiLZv307x8fE0bNgwra5xe0qvXr1o+vTptHfvXpLL5RQbG0srV67U6b4EQBs3bqTa2lr64osvyMjISCsdLi4utG3bNvrf//5HSUlJlJqaSvHx8bRu3Tpyd3cnIyMjauhifpokteZTdelC0QtWVlbw9fUFESErKwu3bt1CeXm5znqHDBkCmUyG9evXY+vWraipqUFwcDD8/Pwgl8v1kPN6unbtitGjR+OXX35BaWmpVjoMDAwwYcIEBAcHw9DQEEB910///v1x/fp1KJVKjXX26NEDQ4cObarhNsIYg7e3NxhjiI6O1iq/jfj4+GD06NFgrLXx7GdjZGSEJUuWYOLEiVi+fDkqKytb/GfQoEHYuHEjNmzYoJFuFxcXvPPOOxg1ahT8/PyQl5encf5aw9LSEps3b0ZAQACEQmFTS6a8vBwlJSUoKSnB/fv3tdLr6OiIIUOGoLi4GPHx8SgoKNBIh1QqRUhICJycnBAVFYWff/4ZxcXFUKlU8Pb2xhtvvIGlS5ciMzNT7VqeQCCAtbU1EhIScOXKFb22kgQCAQYPHoxx48bBxMQEubm5+Oabb0BEUCgUePjwoUb6nJ2dsW3bNrz00ktgjKG8vBwvvfQS+vbti+TkZJw6dUrrvDo6OkIkEuHRo0da26Bbt26YNm0aMjMzsXr1aty5cwe5ubk6t9aeuwP38vLCmjVrIBKJUFNTg5KSEuTl5YEx1nSDEBFKS0vxySefIDMzUy29J0+ehL+/P1JTU1FZWQkLCwvMmjULIpFIr90nDg4OcHV1xebNm3XSsX37dpiZmTWd89tvv42pU6di2bJlOH36tEb6RCIR/Pz8UFpaioqKihbbzczMYGdnp1NXipGREebOnQuxWIyIiAiNC3afPn0wZ84c7N69GzExMS22W1paYvHixYiPj0d0dLTa+k1MTPD+++/jtddeg1AoxFtvvYWtW7eipKREq5tPIpHA398fhYWFuHXrFrp06YKbN28iJycHcXFxSE5Oxt27d5sqHQqFQi29QqEQ3bt3x+TJkzFnzhx069YNUqkUAFBcXIykpCR8/vnnSExMVEufubk5+vbti9jYWKxcuRK3b99u6j778ccfIRaLMWfOHIwePRr79+9XS6dMJoO7uzsiIiJQXV392DaRSASRSASVSoXa2lq19DXf19fXF+Hh4ejevTsAoKqqCq6urnB3d8fu3btx4MABtfWZm5tj0aJFePnll1FVVYVt27YhKSkJq1atgqurK2xtbXUq61VVVSAi5OXlaXyujVy+fBmRkZFwdXXF2bNn1S4nbfK8u1AsLCzI29ubPD09afbs2bRz507au3cvfffdd3TixAk6fvw4nT17liorK7XuVpBKpbR27VqqrKyk77//nkxMTPTSZBMIBLRkyRKKi4sjsVisdd4OHz5MKpWKlEolPXjwgM6cOUNHjx6lgoICunHjBllbW2uk09vbmy5dukTjx49v0SwzNjamzMxM+sc//tFWk+2ZMnz4cCorK6P79++Tg4ODRvvKZDL64osv6KeffiJbW9tW7RocHEw5OTk0YsQItfUyxmjKlClUUFBARUVFpFAoqKamhn755RdydHTU6vq+/fbbdPXqVRo5ciQBIBMTEzIyMiJDQ0OtbWdjY0Pz58+npKQkKioqori4OFq5ciUtWLCAzpw5Q6mpqVRQUEBRUVFql1UvLy+6du0aTZgwodXtrq6ulJOTQ5GRkWrnMywsjLKyssjb27spzdDQkPz8/CgkJIS2bt1K7733Hrm4uGhkU19fX8rMzKSEhAQKDAykfv360YgRI2jr1q2UnZ1No0aN0kjf/PnzqaioiEpKSujvf/87icViYoyRs7MzpaWlUUFBAXl4eGh9vZYvX041NTUUHR2tk++YMGEC/frrr+Tm5kaWlpYklUo12b/VLpTn7sCfFIlEQlKplKysrKhbt24kk8lo06ZNdPPmTXJ2dtbKcIMGDaL09HTKycmhCRMm6OS4mouxsTHt27ePzp49q5VOkUhE8+bNo7y8PKqtraX8/Hz66KOPyMnJiezt7enLL7+ksrIy+vjjj8nS0lItnZaWlrR3716KjIxs1ckEBARQUVERvfbaazqd+6JFi+jRo0e0f/9+MjY21mhfT09PyszMpK1btzbdbM1tMmbMGLp48SJ9+OGHGvVhGxgY0KZNm+j69evk7+9PISEhlJubSzU1NbRp0yYyMDBQW5dQKCQfHx/KzMykjz76iCQSiV7KjFQqpY0bN1JpaSldv36dFixYQK6ursQYIzs7O1q9ejUtXLiQHj58SAqFosUYRmsiFospNDSU0tLSnupMra2tKSYmhmJjY9U+/3379tGRI0dIKpUSY4y6detG4eHhlJeXR0VFRZSamkpyuVyjvmErKyuKiYmhhIQE8vLyaqr49OrVizIzMykiIoJMTU3VtqdYLKbIyEhSKpV0/Pjxx/q7hUIhLViwgORyOYWHh2t9zY4cOUJERDExMVo7cJFIRMuXL6fi4mI6e/YsnThxgnbv3k1+fn4kFArV0dExHPiTMnz4cCopKaHQ0FB1T/QxkclklJCQQGVlZfTGG29odBO3JU5OTnThwgWaO3euVvsbGhpSeHg4VVdX08WLF8nHx+cxp/viiy/SrVu36NGjRzRp0iS1dHp7e1NWVhYFBAS0evNERUXRqVOndBrEbHQGFRUVFBQUpPH+AwYMoEuXLtG9e/fo5MmTtGTJEnrrrbdo4cKFdOjQIcrLy6OrV6/Sn/70J430du3alQ4cOEBbtmwhoVBIBgYGdP78eVKpVPSf//xHo1aSo6MjnTt3jo4ePUpmZmZ6KzNjx44luVxOeXl5NG7cOHJxcSFnZ2dyc3OjqVOn0vfff0/5+fmkVCrp2LFjrQ7uPikODg4UFxdH4eHhTx1oNDMzo8OHD6vtwPv370/Jycm0YMECAkCjRo2i2NhYys/Pp127dpGHhwcZGxvTe++9R+fPn1e7PH366aekUCgoMDCwKa8SiYRWrVpF+fn5FBgYqJE9e/bsSdnZ2aRQKGjKlCkttvfr149SUlJoz549Wg/C6sOBT548mbKzs+nAgQO0aNEiCgoKooiICEpMTKRvv/2WfH1926ok/D4HMZ+FiYkJ3nnnHeTn5+P06dOthsS1xauvvgp3d3ckJibiyJEjqKmp0Vv+xo0bB3Nzc8TFxWmtQyAQQC6XY8mSJfjll18eG7C8ceMGMjMzYW9vj8GDB7c56MgYg4ODA6qrq/Hf//63xfY+ffqgb9++iIyMxL1797TOs42NDezs7JCZmYnz589rvH9GRgbWr1+PSZMmwcfHB0OHDsW1a9egVCpBRLC2tsahQ4eQnJyskV6BQABTU1PY29vDzs4OLi4ucHZ2hlKphIGBAQwMDNTuw7S3t4erqysSExPRo0cPKBQKrcrfkxQXF6O0tBSmpqZYtmwZrKysYGBgACMjI8hkMgD1/eOnT5/G+vXr1RrMs7CwgIWFBQ4ePKi3gUYbGxuYm5vj3r17kEqleP/992Fvb4+wsDAcPHiwadA5NzcXhYWFag86Ojs7o66uDjk5Oairq4NUKsWsWbMQFBSE3NxcnD17VqN8uru7o1u3bjh9+jRiY2NbbFepVKirq4OdnR0sLCxQUlKikf7mZGRktBgLUAfGGO7du4e1a9fiwIEDTeGce/fuRd++fTFp0iSsXr0ax48fx44dO1od0H8av2sHPnDgQLz44ovYtWsXkpKSNN7fyckJ8+fPR2lpKT7++GO9Rp8wxjB8+HCd4n7Nzc3Rr18/VFZWtnC4AoEAbm5ucHFxQV1dnVqRFI0RERUVFbCysmoqbIwxGBgYYNiwYbCxsUFqaqpW+W3Ml4+PD5ycnPDDDz9oFRdcVVWFw4cP4+TJk5DJZBAKhSgrKwNjDPPmzUP37t2xa9cujR+2Dx8+xJkzZxAaGoqYmBh06dIFP/30EyoqKhAQEAAfHx/88MMPaukyNzeHhYUFxowZgz59+iAyMhI3b95EZWUlbt26BSsrK2RkZCA/P1+jga0rV67glVdewZQpU+Dl5YX09HQYGBjAy8ur6QETFRWFkJAQ5OTkqDXwJpVKUVVVhcLCwqf+RyAQQCgUqp1PiUQCQ0NDMMYwcuRI9OrVC+vWrcOePXseO1+pVIrc3Fy1B+VycnLg6+uLNWvWoLS0FGZmZujTpw+sra1x5MgRjSO5ZDIZBAIBzpw5gwcPHrT6H8YYzMzMIJFINNL9JDdv3tTKgRMR4uPjER8f/1i6UqlEamoqbty4gejoaPz73/+GsbExPvnkE7V91e/WgTeO/peVleHrr7/WOJSua9euePPNN+Ho6IgTJ05o9QB4Fvb29hg0aBC2bt2qdfigubk53N3dW33ijh8/Hu+++y66d++O9PR0tZ1uZmYmysvLsW/fPiQkJACot4W9vT3c3d0hEAhw584drfIL1NcO+/fvD4FAgFOnTmld46urq0NZWRnKysqa0lxcXBAYGIivv/5a7Wij5qhUKuzfvx8ODg6YOHEijh8/jg8++ABOTk7w9PTE9OnTER8fr9b1unjxIvbs2YPXXnsNL7zwAlasWNG0rdGpFhQUYN26dfjyyy/VLp9KpRJXrlxBWlpaU9rYsWMxfPhwPHr0CJ9++ik2b96sdplijMHX1xempqbP/F9jeW2tlvo0vUD9uSqVSjDGYG5u/lgr5oUXXsC0adNw6NAhtXQCQFhYGIgIQ4cOhYmJCe7evYuDBw9ixowZOHz4sMaRIg4ODhAIBE2RIq1BRKitrdVLC+q3oLq6GqmpqQgLC8P7778PExMTBAcHq7Xv79aBe3t7Y+bMmdi2bZtWzX07OzvMnDkTFRUVWLt2rcZxtW0xaNAgSKVSnfU23iiNYU6MMUyYMAGhoaEYMmQIHj58iL179+Ly5ctq6cvIyEBwcDAmTZqEbt26AaivOVy4cAGOjo4wNjbGlStXtM6vhYUF/P39UVpaqlNsbWsEBATAzMwMly9f1vrBUFpaijVr1uDQoUPIycmBQqHApUuXcOTIESxcuBDOzs749ddf29Rz+/ZthISEIDo6Gr1790afPn0wbdo0WFhYNF2znj17YtasWYiIiNC4ddfobNzc3BAaGgpbW1tcvHgR4eHhGlcI2orDt7KywsyZM9GlSxfs3r1bLX1mZmYQi8UA6sMQP/vsM8yZMwcikQgbNmyAs7Mzli9fjpqaGkRFRamd16KiIixbtgy2traoq6tDcXExLly4gIqKCuTk5Kitp7U8t4a1tTUsLS2xZ88erWL0ASA/Px8qlQoDBw6ERCLBo0ePtM7nszh//jxcXFwwb948tfdp04EzxuwA7APQHUAdgJ1E9CljLAzA3wE09h+sJCL12qdt8MILLzRNJY+MjNRKh5GREaytrXH//n3IZDKYmJgAAB48eAC5XA4rKyuYmJhg8ODB6NevH4gIEREROHfuXJu1AIFAAA8PD6hUKmRkZGiVP6C+xvjo0SMYGxsjKCgIf/7znzFw4EBIpVJIJBIwxnD9+nVs27ZN7WZ6bW0tLl++jPT09KYms1KphEQiwauvvoqePXvC0tJSo3625gwYMAA2NjY4duyYXqeMSyQSjB07Fj///LNaDvZZ3L9//7GblYiwf/9+TJw4EUFBQUhJSVGre0ahUCAmJgZCoRBWVlaws7PDyJEjsWfPHpiYmGDGjBkwMjLSaiITUB/rHhoaCg8PDxQWFmLVqlUa99ESEbKzs1FTU9Oii8TAwADdu3fHjBkzmipDKSkpaum8c+cOSktL4e3tjQsXLmDXrl24ePEiTExM8Oabb2L+/PnIyspCcHCwxhWshw8fNt03bm5usLa2Rnh4uFb90xEREQgMDMTrr7+OqKiox8okYwwuLi5QqVTYsWOHVt0fIpGoqXXVs2dPiMVirRy4gYEBpFIpHjx48FT/YmFhAQ8PD1y9qsE7cdSIHJEBGNLw3Rj1b+HpCyAMwFJ9R6GIxWLatGkTFRQUUGBgoFaRJwDIzc2N7t27RyqV6jHJzs6muLg4KiwspNraWqqpqaGMjAw6c+YMhYSEqHW8Hj160OnTpykuLk6nabomJib01VdfUXV1NSmVSqqtraXa2lpSKpV0//59iomJoVdeeUVr/c1FKpXSt99+S+Xl5VpPBwZAb7/9Nj148EDnqf5Pir+/P925c4f++c9/kkgk0lvYXqMIhUKaO3cu3b59m0aPHq1x2KdIJKKlS5dSRUUFPXjwgMrLy0kul9P69eu1tqeXlxfl5uZSeXk5LV68WOu5BEOGDKGcnBxasWIFBQYGNsmKFSsoKSmJ7t+/T1FRURqVVbFYTH/961/p7t27dOrUKfriiy8oMjKSsrKyqLCwkDZs2NBqDL8mYmhoSJs3b6Zr165pHafdGKtfWFhIkydPfmxbr169KCUlhbZv36519Jm7uzulpaXpFIXCGKOAgADasmVLi6giiURCAwcOJH9/f/r4448pKiqKnJycWtOjXRQKERUAKGj4rmCMXcNv+OIGHx8fvPrqq/jqq68QHR2tdb9VdnY2li5dCg8PDzDGIJPJMHLkSJiamiIhIQHJycmIj49HdnY2ysrKIJfL8fDhQ7WOZ29vjz59+mDXrl1a938D9TW8bdu2gYjwl7/8BWKxGEqlErW1tdi4cSP27t2LoqIirfU3p3EgU9Mpyk/q6NevH2pqah7ru9YHPXr0gJGRESQSCT744ANcuXIFhw8f1pt+lUqF7777DlOmTMHf/vY3JCYmarRkg1KpxKFDhzBgwAD4+/tDLpdjx44d2LFjh1aLRJmZmWHdunWQyWSIjo7G/v37tZ7lV1BQgPPnz+Pdd999bOkEsViMuro6nDt3DitXrnzqIF9r1NbWIiIiAgqFAqNHj8aIESNw8eJFnDhxAkePHkViYmKrs3w1wcbGBsOHD4dCodA6OqSurg7Hjh3D0KFDsXDhQhQVFeHy5csYMGAAFi9eDJFIhP3792sVfSYUCjF+/Hg4OjoiOTkZGzZs0KrlyhiDu7s7ZsyYAZlMhtTUVFhZWcHU1BS9e/eGqakpqqqqcP78eSxbtkyzwAANa9AOAO4AMEF9DTwHQCqArwCYP2Wf+QCSGuSZTyozMzOKjo4mlUql0WyspwljjAQCAQkEAhIKhSQSiUgkEpFQKNRpYR4XFxcKCwvTeIbk08TIyIimTp1Ku3btoqCgIBo2bJjaE3fUFWtra4qPj6cFCxbodO6zZs2i2NhYnWa2tSYBAQF0/fp1unDhAoWGhur9/Buld+/elJ6eTn5+flpfqylTplD//v11suP06dOpurqa8vLyaNiwYTqfl1QqpdWrV9OxY8ea5IMPPiBPT0+tW7GNIhAISCQSNd1L+roWHh4edPXqVVq7dq3OuoyNjSksLIx+/PFH2rdvHyUnJ9O5c+do5syZWreQhEIhzZo1i4KDg3VqtQL1vm3atGm0dOlSOnjwIH322We0fPlymj17Nrm6upKVlVVbttVtIg8AKYBkAH9u+G2D+mVkBQDWon45WZ26UMaMGUNyuZzkcjm99NJLeisoXOqbqx4eHjpNAQdAXbp0IU9PT71ObgHqJ+H4+PhQ79699bqC4JNiYGBAGzZsoKVLl+rs2HSR3bt3U3V1Na1bt06vk8s6kowePZpu375NM2fO1Is+IyMjGjhwIM2cOZM8PT3J1tZWb7OufweivQMHIEb9ut9LnlEzT9PVgY8dO5bi4uJo3rx5OjsaLlyeJl26dNHbejjaytSpUykqKorc3Nyeuz2elzg4ONCWLVto0KBBzz0vHUBadeCsrYgLVj/EvhdAKREtbpYua+gfB2PsXQCeRDS9DV3PPhiHw+FwWiOZiIY9mahOHPjLAOYAuMIYu9SQthLADMbYINQ/HXIAvKmXbHI4HA5HLdqsgev1YIwpANxotwN2HKwAaL9Iwx8TbpPW4XZpSWewiT3p+a302nCjtWZAZ4cxlsTt8jjcJq3D7dKSzmwTQdt/4XA4HM7vEe7AORwOp4PS3g58Zzsfr6PA7dISbpPW4XZpSae1SbsOYnI4HA5Hf/AuFA6Hw+mgtJsDZ4yNZ4zdYIzdZIwtb6/jPm8YY18xxooYY2nN0iwYYz8yxjIbPs2bbVvRYKMbjLFxzyfXvy2MMTvG2DnG2DXGWDpjbFFDeme3ixFjLIExdrnBLqsa0ju1XQCAMSZkjKUwxqIbfnd6mwCAXl5WrMYUeiGALAC9ABgAuAygb3sc+3kLAG8AQ9BsqQEAGwEsb/i+HMCGhu99G2xjCMCxwWbC530Ov4FNnrZEcWe3CwMgbfguBvArgBc7u10aznUJgP8AiG743eltQkTtVgMfDuAmEd0iohoAEQAmt9OxnytEFAvgyTVnJ6N+eQI0fE5plh5BRNVElA3gJupt94eCiAqI6GLDdwWAxiWKO7tdiIga12gVNwihk9uFMWYLYCKA5q8T6tQ2aaS9HHhPAHeb/c7Fb7imeAfAhhrWkWn47NaQ3unsxBhzADAY9bXNTm+Xhq6CSwCKAPxIRNwuwCcAQlD/RrBGOrtNALSfA2/tnVM8/KUlncpOjDEpgKMAFhPRs96u0GnsQkQqIhoEwBbAcMZY/2f8/Q9vF8bYJABFRJSs7i6tpP2hbNKc9nLguQDsmv22BZDfTsf+PXKPMSYD6ld1RH1tC+hEdmKMiVHvvA8S0bGG5E5vl0aIqAzAfwGMR+e2y8sAXmGM5aC+63UUY+wAOrdNmmgvB54IwJkx5sgYMwAwHcB37XTs3yPfAXi94fvrAKKapU9njBkyxhwBOANIeA75+01pWKL4SwDXiGhLs02d3S7WjDGzhu8SAGMAXEcntgsRrSAiWyJyQL3fOEtEs9GJbfIY7TiKPAH10QZZAN573qO37Xjeh1D/TtFa1NcOggBYAvgJQGbDp0Wz/7/XYKMbAPyfd/5/I5uMQH2zNhXApQaZwO2CAQBSGuySBiC0Ib1T26XZufri/6NQuE1IjRc6cDgcDuf3CZ+JyeFwOB0U7sA5HA6ng8IdOIfD4XRQuAPncDicDgp34BwOh9NB4Q6cw+FwOijcgXM4HE4HhTtwDofD6aD8H8kj7NW8MRsBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp : \n",
      "tensor([ True,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True,  True,  True])\n",
      "shape : torch.Size([16])\n",
      "7855/10000\n",
      "Accuracy : 0.7854999899864197\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images, nrow=batch_size))\n",
    "\n",
    "n_predict = 0\n",
    "n_correct = 0\n",
    "\n",
    "for i,data in enumerate(test_loader) :\n",
    "    inputs, labels = data\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs,1) # indices\n",
    "    \n",
    "    n_predict += len(predicted)\n",
    "    if(i == 0):\n",
    "        temp = (labels == predicted)\n",
    "        print(f\"temp : \\n{temp}\\nshape : {temp.shape}\")\n",
    "    n_correct += (labels == predicted).sum()\n",
    "\n",
    "print(f\"{n_correct}/{n_predict}\")\n",
    "print(f\"Accuracy : {n_correct/n_predict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada53b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
